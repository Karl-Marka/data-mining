{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc,recall_score,precision_score,accuracy_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "probs = pd.read_parquet('./probs.parquet', engine='pyarrow')\n",
    "normals = pd.read_parquet('./normals.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for variable engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pident = set(probs.ident.unique())\n",
    "nident = set(normals.ident.unique())\n",
    "\n",
    "probs_coding = {}\n",
    "norms_coding = {}\n",
    "i = 0\n",
    "for ident in list(pident): \n",
    "    probs_coding[ident] = i\n",
    "    i += 1\n",
    "\n",
    "for ident in list(nident):\n",
    "    norms_coding[ident] = i\n",
    "    i += 1\n",
    "    \n",
    "probs['id'] = probs.ident.apply(lambda x: probs_coding[x])\n",
    "normals['id'] = normals.ident.apply(lambda x: norms_coding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([probs, normals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del probs, normals\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.event_id = df.event_id.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save unix time as an index to keep the order of events\n",
    "df['index'] = df.start.copy()\n",
    "df.start = df.start.astype('M8[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating timedeltas\n",
    "def group_timedelta(group):\n",
    "    group.sort_values('index', inplace=True)\n",
    "    group['timedelta'] = group.start - group.start.shift()\n",
    "    group.timedelta.fillna(0, inplace=True)\n",
    "    return group\n",
    "\n",
    "def make_timedelta(df):\n",
    "    df = df.groupby('id', as_index=False).apply(group_timedelta)\n",
    "    df = df.reset_index().iloc[:,2:]\n",
    "    df.timedelta = df.timedelta.dt.seconds\n",
    "    return df\n",
    "\n",
    "df = make_timedelta(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.timedelta = pd.cut(df.timedelta, [0,1,5,60,300,1800,3600,3600*5,3600*24], right=False)\n",
    "df.timedelta = df.timedelta.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['weekday'] = df.start.dt.weekday_name\n",
    "df['hour'] = df.start.dt.hour.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the device info\n",
    "phone_models = pd.read_msgpack('./phone_models.msgpack')\n",
    "\n",
    "device_info = phone_models.loc[:,phone_models.columns.drop(['phone_id', 'allocation_date', 'storage_code', 'handsetmodel_id', 'phone_cnt', 'g3', 'g4', 'android'])]\n",
    "device_info.rename(columns={'seadme_tyyp': 'network_type'}, inplace=True)\n",
    "\n",
    "df = df.merge(device_info, on='TAC')\n",
    "df.drop(labels=['TAC'], axis=1, inplace=True)\n",
    "df.nfc = df.nfc.astype(str).apply(lambda x: None if x == 'nan' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming from categorical to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = ['event_result', 'cause_code', 'sub_cause_code', 'mecontext', 'event_id', 'network_type', 'phone_type', 'Manufacturer', 'Model', 'os', 'category', 'nfc', 'sim_type', 'screen_size', 'timedelta', 'weekday', 'hour']\n",
    "non_cats = ['index', 'id', 'ident', 'start', 'probs']\n",
    "def encode_columns(df):\n",
    "    return pd.concat([df[non_cats], pd.get_dummies(df[cats], cats, dummy_na = True)], axis=1)\n",
    "\n",
    "df = encode_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating random sets of ids for the training and testing set - these need to be kept separate in both the\n",
    "# non-aggregated and aggregated datasets\n",
    "probs_indexes = random.sample(range(500), 100)\n",
    "normals_indexes = random.sample(range(500,5500), 1000)\n",
    "test_indexes = probs_indexes + normals_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(id, test = test_indexes):\n",
    "    if id in test_indexes:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['test'] = df['id'].apply(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.loc[df['test'] == 0]\n",
    "df_test = df.loc[df['test'] == 1]\n",
    "del df_train['test']\n",
    "del df_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating the single events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following steps should also be done for the competition dataset, but removing the 'probs' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouping the variables by information source\n",
    "non_cats = ['index', 'id', 'ident', 'start', 'probs'] # - remove 'probs' from the list for the competition dataset\n",
    "identical = ['id', 'ident', 'probs']  # - remove 'probs' from the list for the competition dataset\n",
    "event_result = [x for x in df.columns.tolist() if x.startswith('event_result')]\n",
    "cause_code = [x for x in df.columns.tolist() if x.startswith('cause_code')]\n",
    "sub_cause_code = [x for x in df.columns.tolist() if x.startswith('sub_cause_code')]\n",
    "event_id = [x for x in df.columns.tolist() if x.startswith('event_id')]\n",
    "network_type = [x for x in df.columns.tolist() if x.startswith('network_type')]\n",
    "phone_type = [x for x in df.columns.tolist() if x.startswith('phone_type')]\n",
    "Manufacturer = [x for x in df.columns.tolist() if x.startswith('Manufacturer')]\n",
    "Model = [x for x in df.columns.tolist() if x.startswith('Model')]\n",
    "os = [x for x in df.columns.tolist() if x.startswith('os')]\n",
    "category = [x for x in df.columns.tolist() if x.startswith('category')]\n",
    "nfc = [x for x in df.columns.tolist() if x.startswith('nfc')]\n",
    "sim_type = [x for x in df.columns.tolist() if x.startswith('sim_type')]\n",
    "screen_size = [x for x in df.columns.tolist() if x.startswith('screen_size')]\n",
    "timedelta = [x for x in df.columns.tolist() if x.startswith('timedelta')]\n",
    "weekday = [x for x in df.columns.tolist() if x.startswith('weekday')]\n",
    "hour = [x for x in df.columns.tolist() if x.startswith('hour')]\n",
    "history = [x for x in df.columns.tolist() if x.startswith('history')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_lists(list_of_lists):\n",
    "    list3 = []\n",
    "    if type(list_of_lists) is list:\n",
    "        for element in list_of_lists:\n",
    "            list3.extend(element)\n",
    "    else:\n",
    "        list3.extend(list_of_lists)\n",
    "    return list(set(list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determining which variables will be summed and which ones will be averaged\n",
    "identical_info = join_lists([identical, weekday])\n",
    "event_info = join_lists([event_result, cause_code, sub_cause_code, event_id])\n",
    "device_info = join_lists([network_type, phone_type, Manufacturer, Model, os, category, nfc, sim_type, screen_size])\n",
    "time_info = join_lists([timedelta, weekday, hour])\n",
    "\n",
    "summable = join_lists([event_info, timedelta, hour])\n",
    "meanable = join_lists([event_info, device_info, timedelta, hour])\n",
    "\n",
    "summable.append('id')\n",
    "meanable.append('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggregating the data\n",
    "df_daily = pd.concat([df[identical_info].groupby('id').mean(), df[summable].groupby('id').sum().rename(columns = dict(zip(df[summable].groupby('id').sum().columns, ['sum_' + x for x in df[summable].groupby('id').sum().columns]))), df[meanable].groupby('id').mean().rename(columns = dict(zip(df[meanable].groupby('id').mean().columns, ['mean_' + x for x in df[meanable].groupby('id').mean().columns])))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the data for later use:\n",
    "# df_daily.to_csv('df_competition_historical_data.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the aggregated data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_agg = df_daily.loc[test_indexes,:]\n",
    "df_train_agg = df_daily.loc[~df.index.isin(df_train_agg.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting outcomes for single events to use the aggregated predictions as variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature selection with ANOVA f-test\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "f_values, f_p_values = f_classif(np.array(X_train_subsample),np.array(y_train_subsample))\n",
    "selected_features = X_train_subsample.columns[f_values > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train['probs']\n",
    "y_test = df_test['probs']\n",
    "id_train = df_train['id']\n",
    "id_test = df_test['id']\n",
    "X_train = df_train[selected_features]\n",
    "X_test = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a simple random forest classifer for this large dataset:\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 3, n_jobs = 16, verbose = 10)\n",
    "model.fit(X_train, y_train)\n",
    "check = model.predict_proba(X_test)\n",
    "train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggregating the predictions\n",
    "result_train = pd.DataFrame(data=[])\n",
    "result_train['id']= id_train\n",
    "result_train['pred'] = train[:,1]\n",
    "\n",
    "train_mean = result_train.groupby('id').mean()\n",
    "train_mean.columns = ['pred_mean']\n",
    "\n",
    "train_max = result_train.groupby('id').max()\n",
    "train_max.columns = ['pred_max']\n",
    "\n",
    "# ...and for the testing set\n",
    "result_test = pd.DataFrame(data=[])\n",
    "result_test['id']= id_test\n",
    "result_test['pred'] = check[:,1]\n",
    "\n",
    "test_mean = result_test.groupby('id').mean()\n",
    "test_mean.columns = ['pred_mean']\n",
    "\n",
    "test_max = result_test.groupby('id').max()\n",
    "test_max.columns = ['pred_max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding single event predictions to the training data:\n",
    "data = df_train_agg.merge(train_mean, on='id')\n",
    "data = df_train_agg.merge(train_max, on='id')\n",
    "data.columns = [x.replace('[', '').replace(']', '') for x in data.columns]\n",
    "\n",
    "# ... and the test data:\n",
    "test = df_test_agg.merge(test_mean, on='id')\n",
    "test = df_test_agg.merge(test_max, on='id')\n",
    "test.columns = [x.replace('[', '').replace(']', '') for x in test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the feature importances\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "f_values, f_p_values = f_classif(np.array(X_train),np.array(y_train))\n",
    "selected_features = X_train.columns[f_values > 65]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The variables that will be used for the modeling:\n",
    "cols = ['sum_sub_cause_code_NO_VALUE',\n",
    " 'sum_sub_cause_code_SIGNALING_INTERFERENCE',\n",
    " 'sum_sub_cause_code_SUBSCRIPTION_CANCELLED',\n",
    " 'sum_cause_code_UNKNOWN_CAUSE_CODE_PROT_TYPE_0',\n",
    " 'sum_sub_cause_code_SGSN_CONTEXT_REQUEST_RECEIVED',\n",
    " 'sum_event_id_13',\n",
    " 'sum_event_id_2',\n",
    " 'sum_event_result_IGNORE',\n",
    " 'sum_event_id_15',\n",
    " 'sum_sub_cause_code_GGSN_RESPONDED_WITH_REJECT_CAUSE_CONTEXT_NON_EXISTENT',\n",
    " 'sum_sub_cause_code_QOS_CHANGED_BY_GGSN_DURING_RAU_OR_SGSN_OR_BSS_MODIFICATION_PROCEDURE',\n",
    " 'sum_cause_code_REACTIVATION_REQUIRED',\n",
    " 'sum_sub_cause_code_TIMEOUT_PAGING',\n",
    " 'sum_event_id_8',\n",
    " 'sum_sub_cause_code_NO_RESPONSE_FROM_MS_DURING_SGSN_INITIATED_MODIFICATION',\n",
    " 'mean_sub_cause_code_SIGNALING_INTERFERENCE',\n",
    " 'mean_event_id_4',\n",
    " 'mean_event_id_6',\n",
    " 'mean_event_id_2',\n",
    " 'mean_timedelta_0, 1)',\n",
    " 'mean_event_id_5',\n",
    " 'mean_event_id_8',\n",
    " 'mean_cause_code_UNKNOWN_CAUSE_CODE_PROT_TYPE_0',\n",
    " 'mean_event_id_13',\n",
    " 'mean_sub_cause_code_QOS_CHANGED_BY_GGSN_DURING_RAU_OR_SGSN_OR_BSS_MODIFICATION_PROCEDURE',\n",
    " 'mean_event_id_12',\n",
    " 'mean_cause_code_REACTIVATION_REQUIRED',\n",
    " 'mean_event_result_ABORT',\n",
    " 'mean_sub_cause_code_NO_VALUE',\n",
    " 'mean_timedelta_60, 300)',\n",
    " 'mean_sub_cause_code_SGSN_CONTEXT_REQUEST_RECEIVED',\n",
    " 'mean_sub_cause_code_SUCCESS',\n",
    " 'mean_cause_code_NOCAUSECODE',\n",
    " 'mean_sub_cause_code_DETACH_TRIGGERED_PDN_DISCONNECTION',\n",
    " 'mean_event_result_IGNORE',\n",
    " 'mean_sub_cause_code_NO_RESPONSE_FROM_MS_DURING_SGSN_INITIATED_MODIFICATION',\n",
    " 'pred_mean',\n",
    " 'pred_max',\n",
    " 'sum_hour_22',\n",
    " 'sum_hour_14',\n",
    " 'mean_hour_13',\n",
    " 'weekday_Friday',\n",
    " 'mean_hour_21',\n",
    " 'mean_hour_16',\n",
    " 'weekday_Saturday',\n",
    " 'mean_hour_23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train_agg['probs']\n",
    "y_test = df_test_agg['probs']\n",
    "\n",
    "X_train = df_train_agg[cols]\n",
    "X_test = df_test_agg[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Oversampling the minority 'probs' = True class for training\n",
    "sm = SMOTE(ratio = {True:(4*y_train.sum())},k_neighbors=5, random_state=np.random.randint(567))\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "X_train = pd.DataFrame(data=X_train, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost classifer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning the hyperparameters\n",
    "parameter_ranges = {'max_depth': [3,5,10],\n",
    "                   'learning_rate': [0.01, 0.05, 0.1],\n",
    "                   'n_estimators': [50, 100, 500]}\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier().fit(X_train, y_train)\n",
    "model_tuned = GridSearchCV(model, parameter_ranges, scoring = 'roc_auc', verbose = 10, n_jobs = 16)\n",
    "model_tuned.fit(X_train, y_train)\n",
    "model_xgb = model_tuned.best_estimator_ \n",
    "print(model_tuned.best_score_)\n",
    "print(model_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning the hyperparameters\n",
    "parameter_ranges = {'max_depth': [10,15,20],\n",
    "                   'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train, y_train)\n",
    "model_tuned = GridSearchCV(model, parameter_ranges, scoring = 'roc_auc', verbose = 10, n_jobs = 16)\n",
    "model_tuned.fit(X_train, y_train)\n",
    "model_rf = model_tuned.best_estimator_ \n",
    "print(model_tuned.best_score_)\n",
    "print(model_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making the predictions for the test set:\n",
    "predictions_xgb = model_xgb.predict_proba(X_test)\n",
    "predictions_rf = model_rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking the max probability for class 'probs' = True\n",
    "predictions_final = [np.max([x,y]) for x,y in zip(predictions_xgb[:,1], predictions_rf[:,1])]\n",
    "predictions_final_binary = [1 if x >= 0.52 else 0 for x in predictions_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the accuracy metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#area under the precision-recall curve\n",
    "score = average_precision_score(y_test, predictions_final)\n",
    "print('area under the precision-recall curve: {:.6f}'.format(score))\n",
    "\n",
    "\n",
    "check2 = predictions_final_binary\n",
    "score = precision_score(y_test, check2)\n",
    "print('precision score: {:.6f}'.format(score))\n",
    "\n",
    "score = recall_score(y_test, check2)\n",
    "print('recall score: {:.6f}'.format(score))\n",
    "\n",
    "score = accuracy_score(y_test, check2)\n",
    "print('accuracy score: {:.6f}'.format(score))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, predictions_final)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training all the classifiers on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the single event classifer:\n",
    "X_full = df[selected_features]\n",
    "y_full = df['probs']\n",
    "model = model.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the aggregated data classifers:\n",
    "X_full = df_daily[cols]\n",
    "y_full = df_daily['probs']\n",
    "model_xgb = model_xgb.fit(X_full, y_full)\n",
    "model_rf = model_rf.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the models for later use:\n",
    "joblib.dump(model, './final_models/nonagg_full_model.pkl')\n",
    "joblib.dump(model_xgb, './final_models/model_xgb.pkl')\n",
    "joblib.dump(model_rf, './final_models/model_rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the predictions for the competition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "competition = pd.read_parquet('./competition_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file is created using the same lines of code used to aggregate the training data\n",
    "# The steps used though \"aggregating the single events\" should be used\n",
    "competition_agg = pd.read_csv('./df_competition_historical_data.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading in the saved models:\n",
    "model = joblib.load('./final_models/nonagg_full_model.pkl')\n",
    "model_xgb = joblib.load('./final_models/model_xgb.pkl')\n",
    "model_rf = joblib.load('./final_models/model_rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation - same steps as in the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nident = set(competition.ident.unique())\n",
    "\n",
    "norms_coding = {}\n",
    "i = 0\n",
    "\n",
    "for ident in list(nident):\n",
    "    norms_coding[ident] = i\n",
    "    i += 1\n",
    "    \n",
    "competition['id'] = competition.ident.apply(lambda x: norms_coding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "competition.event_id = competition.event_id.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "competition['index'] = competition.start.copy()\n",
    "competition.start = competition.start.astype('M8[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_timedelta(group):\n",
    "    group.sort_values('index', inplace=True)\n",
    "    group['timedelta'] = group.start - group.start.shift()\n",
    "    group.timedelta.fillna(0, inplace=True)\n",
    "    return group\n",
    "\n",
    "def make_timedelta(df):\n",
    "    df = df.groupby('id', as_index=False).apply(group_timedelta)\n",
    "    df = df.reset_index().iloc[:,2:]\n",
    "    df.timedelta = df.timedelta.dt.seconds\n",
    "    return df\n",
    "\n",
    "competition = make_timedelta(competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "competition.timedelta = pd.cut(competition.timedelta, [0,1,5,60,300,1800,3600,3600*5,3600*24], right=False)\n",
    "competition.timedelta = competition.timedelta.astype(str)\n",
    "competition['weekday'] = competition.start.dt.weekday_name\n",
    "competition['hour'] = competition.start.dt.hour.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phone_models = pd.read_msgpack('./phone_models.msgpack')\n",
    "\n",
    "device_info = phone_models.loc[:,phone_models.columns.drop(['phone_id', 'allocation_date', 'storage_code', 'handsetmodel_id', 'phone_cnt', 'g3', 'g4', 'android'])]\n",
    "device_info.rename(columns={'seadme_tyyp': 'network_type'}, inplace=True)\n",
    "\n",
    "competition = competition.merge(device_info, on='TAC')\n",
    "competition.drop(labels=['TAC'], axis=1, inplace=True)\n",
    "competition.nfc = competition.nfc.astype(str).apply(lambda x: None if x == 'nan' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = ['event_result', 'cause_code', 'sub_cause_code', 'mecontext', 'event_id', 'network_type', 'phone_type', 'Manufacturer', 'Model', 'os', 'category', 'nfc', 'sim_type', 'screen_size', 'timedelta', 'weekday', 'hour']\n",
    "non_cats = ['index', 'id', 'ident', 'start']\n",
    "def encode_columns(df):\n",
    "    return pd.concat([df[non_cats], pd.get_dummies(df[cats], cats, dummy_na = True)], axis=1)\n",
    "\n",
    "competition = encode_columns(competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apparently this model does not appear in the competition dataset so I'm adding all zeros\n",
    "competition['Model_GQ3030'] = len(competition.index) * [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = competition[['id', 'cause_code_EPS_SERVICES_NOT_ALLOWED_IN_THIS_PLMN',\n",
    "       'cause_code_NOCAUSECODE', 'cause_code_REACTIVATION_REQUIRED',\n",
    "       'cause_code_SUCCESSFUL_HANDOVER',\n",
    "       'cause_code_UNKNOWN_CAUSE_CODE_PROT_TYPE_0',\n",
    "       'sub_cause_code_ALL_PACKET_ORIENTED_SERVICES_BARRED',\n",
    "       'sub_cause_code_NO_VALUE',\n",
    "       'sub_cause_code_QOS_CHANGED_BY_GGSN_DURING_RAU_OR_SGSN_OR_BSS_MODIFICATION_PROCEDURE',\n",
    "       'sub_cause_code_SUCCESS', 'event_id_0', 'event_id_1', 'event_id_13',\n",
    "       'event_id_15', 'event_id_2', 'event_id_4', 'event_id_5', 'event_id_6',\n",
    "       'event_id_7', 'event_id_8', 'network_type_3G', 'network_type_4G',\n",
    "       'phone_type_Nutitelefon', 'phone_type_[No Data]', 'Manufacturer_Apple',\n",
    "       'Manufacturer_Samsung', 'Manufacturer_Teised', 'Manufacturer_ZTE',\n",
    "       'Model_Alcatel Onetouch Pop 8S', 'Model_Apple iPhone 7 (A1778)',\n",
    "       'Model_Apple iPhone X 64GB', 'Model_BV7000', 'Model_CAT S41',\n",
    "       'Model_CAT S60', 'Model_Coolpad Modena', 'Model_E303', 'Model_GQ3030',\n",
    "       'Model_HUAWEI Y6 Pro', 'Model_Huawei P9 Lite', 'Model_LG G4 Stylus',\n",
    "       'Model_Lenovo A6000', 'Model_Lenovo Z90-7', 'Model_Maya-L41',\n",
    "       'Model_MediaPad S7-303u', 'Model_Nokia LUMIA 635',\n",
    "       'Model_Original One, Original Pure, Original Shock, Kindo',\n",
    "       'Model_PM-1023-BV', 'Model_SM-G800F Galaxy S5 mini',\n",
    "       'Model_Samsung Galaxy Alpha 32GB', 'Model_Sony Xperia XA',\n",
    "       'Model_ZTE Blade V6', 'Model_iPhone 6 (A1586)', 'Model_m3 note',\n",
    "       'os_Android', 'os_Windows', 'os_iOS', 'nfc_0.0', 'nfc_1.0',\n",
    "       'sim_type_mini', 'sim_type_nan', 'screen_size_4.7', 'screen_size_5.0',\n",
    "       'screen_size_5.0000', 'screen_size_5.2000', 'screen_size_7.0',\n",
    "       'screen_size_nan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=16)]: Done  53 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=16)]: Done  66 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=16)]: Done  80 out of 100 | elapsed:   18.2s remaining:    4.5s\n",
      "[Parallel(n_jobs=16)]: Done  91 out of 100 | elapsed:   20.0s remaining:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:   21.9s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_proba(data.drop(['id'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregating the single event predictions\n",
    "result = pd.DataFrame(data=[])\n",
    "result['id']= data['id']\n",
    "result['pred'] = predictions[:,1]\n",
    "\n",
    "result_mean = result.groupby('id').mean()\n",
    "result_mean.columns = ['pred_mean']\n",
    "\n",
    "result_max = result.groupby('id').max()\n",
    "result_max.columns = ['pred_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating the id column so I can easily merge\n",
    "result_mean['id'] = result_mean.index\n",
    "result_max['id'] = result_max.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = competition_agg.merge(result_mean, on='id')\n",
    "data = data.merge(result_max, on='id')\n",
    "data.columns = [x.replace('[', '').replace(']', '') for x in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selecting the variables to be used with the aggregated data models\n",
    "data = data[['sum_sub_cause_code_NO_VALUE',\n",
    " 'sum_sub_cause_code_SIGNALING_INTERFERENCE',\n",
    " 'sum_sub_cause_code_SUBSCRIPTION_CANCELLED',\n",
    " 'sum_cause_code_UNKNOWN_CAUSE_CODE_PROT_TYPE_0',\n",
    " 'sum_sub_cause_code_SGSN_CONTEXT_REQUEST_RECEIVED',\n",
    " 'sum_event_id_13',\n",
    " 'sum_event_id_2',\n",
    " 'sum_event_result_IGNORE',\n",
    " 'sum_event_id_15',\n",
    " 'sum_sub_cause_code_GGSN_RESPONDED_WITH_REJECT_CAUSE_CONTEXT_NON_EXISTENT',\n",
    " 'sum_sub_cause_code_QOS_CHANGED_BY_GGSN_DURING_RAU_OR_SGSN_OR_BSS_MODIFICATION_PROCEDURE',\n",
    " 'sum_cause_code_REACTIVATION_REQUIRED',\n",
    " 'sum_sub_cause_code_TIMEOUT_PAGING',\n",
    " 'sum_event_id_8',\n",
    " 'sum_sub_cause_code_NO_RESPONSE_FROM_MS_DURING_SGSN_INITIATED_MODIFICATION',\n",
    " 'mean_sub_cause_code_SIGNALING_INTERFERENCE',\n",
    " 'mean_event_id_4',\n",
    " 'mean_event_id_6',\n",
    " 'mean_event_id_2',\n",
    " 'mean_timedelta_0, 1)',\n",
    " 'mean_event_id_5',\n",
    " 'mean_event_id_8',\n",
    " 'mean_cause_code_UNKNOWN_CAUSE_CODE_PROT_TYPE_0',\n",
    " 'mean_event_id_13',\n",
    " 'mean_sub_cause_code_QOS_CHANGED_BY_GGSN_DURING_RAU_OR_SGSN_OR_BSS_MODIFICATION_PROCEDURE',\n",
    " 'mean_event_id_12',\n",
    " 'mean_cause_code_REACTIVATION_REQUIRED',\n",
    " 'mean_event_result_ABORT',\n",
    " 'mean_sub_cause_code_NO_VALUE',\n",
    " 'mean_timedelta_60, 300)',\n",
    " 'mean_sub_cause_code_SGSN_CONTEXT_REQUEST_RECEIVED',\n",
    " 'mean_sub_cause_code_SUCCESS',\n",
    " 'mean_cause_code_NOCAUSECODE',\n",
    " 'mean_sub_cause_code_DETACH_TRIGGERED_PDN_DISCONNECTION',\n",
    " 'mean_event_result_IGNORE',\n",
    " 'mean_sub_cause_code_NO_RESPONSE_FROM_MS_DURING_SGSN_INITIATED_MODIFICATION',\n",
    " 'pred_mean',\n",
    " 'pred_max',\n",
    " 'sum_hour_22',\n",
    " 'sum_hour_14',\n",
    " 'mean_hour_13',\n",
    " 'weekday_Friday',\n",
    " 'mean_hour_21',\n",
    " 'mean_hour_16',\n",
    " 'weekday_Saturday',\n",
    " 'mean_hour_23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicting probabilities:\n",
    "predictions_xgb = model_xgb.predict_proba(data)\n",
    "predictions_rf = model_rf.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating lists of probabilities and final predictions\n",
    "predictions_final = [np.max([x,y]) for x,y in zip(predictions_xgb[:,1], predictions_rf[:,1])]\n",
    "predictions_final_binary = [True if x >= 0.52 else False for x in predictions_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# joining the ids and predictions into single dataframe\n",
    "predictions = pd.DataFrame(data=[])\n",
    "predictions['ident'] = competition_agg['id']\n",
    "predictions['probs'] = predictions_final_binary\n",
    "predictions['probs_probability'] = predictions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11080383480825959"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the distribution is about the same as in training dataset (10%)\n",
    "predictions['probs'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding the predictions to the competition dataset\n",
    "competition_results = competition.merge(predictions, on = 'ident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12554338586281305"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_results['probs'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13905381070197795"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_results['probs_probability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the results\n",
    "competition_results.to_parquet('./competition_results.parquet')\n",
    "predictions.to_csv('./results.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
